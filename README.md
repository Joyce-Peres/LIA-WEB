# LIA Web - Libras com InteligÃªncia Artificial

Plataforma web responsiva que ensina LÃ­ngua Brasileira de Sinais (Libras) utilizando reconhecimento de gestos em tempo real com processamento 100% local no navegador.

## ğŸ¯ Sobre o Projeto

O LIA Web Ã© uma aplicaÃ§Ã£o educacional que utiliza visÃ£o computacional e deep learning para fornecer feedback automÃ¡tico no aprendizado de Libras. A plataforma processa o vÃ­deo da webcam localmente no navegador, garantindo privacidade e latÃªncia mÃ­nima (<50ms).

**CaracterÃ­sticas principais:**
- âœ… Reconhecimento de gestos em tempo real com modelo LSTM
- âœ… Processamento 100% local (privacidade por padrÃ£o)
- âœ… AcurÃ¡cia >93% no reconhecimento de sinais
- âœ… Interface gamificada com sistema de XP, badges e streaks
- âœ… Sem necessidade de backend (MVP totalmente client-side)

## ğŸš€ Tecnologias

- **Frontend:** Angular 21 + TypeScript
- **Build:** Angular CLI + esbuild
- **Styling:** CSS moderno + componentes customizados
- **Machine Learning:** TensorFlow.js + MediaPipe Hands
- **Testes:** Jest
- **Backend (MVP):** nenhum (modo local â€” sessÃ£o e dados no navegador)
- **Deployment:** host de arquivos estÃ¡ticos

## ğŸ“‹ PrÃ©-requisitos

- Node.js 20+ 
- npm 11.6.2+
- Webcam funcional
- Navegador moderno com suporte a WebGL (Chrome, Edge, Firefox)

## âš™ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/Joyce-Peres/LIA-WEB.git
cd LIA-WEB/lia-web
```

2. Instale as dependÃªncias:

```bash
npm install
```

3. Inicie o servidor de desenvolvimento:

```bash
npm start
```

O aplicativo estarÃ¡ disponÃ­vel em `http://localhost:4200`

## ğŸ—ï¸ Estrutura do Projeto

```
lia-web/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # MÃ³dulos Angular
â”‚   â”‚   â”œâ”€â”€ components/         # Componentes da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ services/           # ServiÃ§os (AI, camera, auth)
â”‚   â”‚   â”œâ”€â”€ models/             # Interfaces e tipos TypeScript
â”‚   â”‚   â””â”€â”€ pages/              # PÃ¡ginas/rotas principais
â”‚   â”œâ”€â”€ assets/                 # Recursos estÃ¡ticos
â”‚   â”‚   â”œâ”€â”€ models/             # Modelos TensorFlow.js convertidos
â”‚   â”‚   â””â”€â”€ images/             # Imagens e Ã­cones
â”‚   â””â”€â”€ environments/           # ConfiguraÃ§Ãµes de ambiente
â”œâ”€â”€ scripts/                    # Scripts Python para ML
â”‚   â”œâ”€â”€ coletar_gestos.py      # Coleta de dados de treinamento
â”‚   â”œâ”€â”€ treinar_modelo.py      # Treinamento do modelo LSTM
â”‚   â””â”€â”€ converter_simples.py   # ConversÃ£o para TensorFlow.js
â”œâ”€â”€ modelos/                    # Modelos Python originais (.h5)
â”œâ”€â”€ dados/                      # Datasets de treinamento
â””â”€â”€ public/                     # Arquivos pÃºblicos estÃ¡ticos
```

## ğŸ“ Scripts DisponÃ­veis

### Desenvolvimento Web
- `npm start` - Inicia servidor de desenvolvimento (localhost:4200)
- `npm run build` - Cria build de produÃ§Ã£o
- `npm run watch` - Build em modo watch
- `npm test` - Executa testes com Jest
- `npm run test:watch` - Executa testes em modo watch

### Machine Learning (Python)
Para trabalhar com o pipeline de ML, consulte [SETUP-AMBIENTE.md](lia-web/SETUP-AMBIENTE.md).

```powershell
# Ativar ambiente virtual Python
.\scripts\venv_coleta\Scripts\Activate.ps1

# Coletar dados de gestos
python scripts/coletar_gestos.py

# Treinar modelo LSTM
python scripts/treinar_modelo.py

# Converter modelo para TensorFlow.js
python scripts/converter_simples.py
```

## ğŸ¯ Funcionalidades

### Implementadas âœ…
- AutenticaÃ§Ã£o local (sem serviÃ§os externos)
- Captura de vÃ­deo da webcam a 30 FPS
- ExtraÃ§Ã£o de landmarks das mÃ£os via MediaPipe Hands (21 pontos x,y,z por mÃ£o)
- Buffer circular com Ãºltimos 30 frames de landmarks
- Carga e execuÃ§Ã£o do modelo LSTM com TensorFlow.js
- NormalizaÃ§Ã£o de landmarks para shape [1, 30, 126]
- PÃ³s-processamento com threshold (0.85) e debounce
- Interface responsiva e acessÃ­vel

### Em Desenvolvimento â³
- Sistema de perfil do usuÃ¡rio completo
- CatÃ¡logo de mÃ³dulos e liÃ§Ãµes estruturado
- Interface gamificada de aprendizado
- Sistema de pontuaÃ§Ã£o e feedback visual
- Badges e sistema de conquistas
- PersistÃªncia de progresso entre sessÃµes

### Planejadas ğŸ“‹
- Modo PWA (Progressive Web App)
- Suporte offline completo
- SincronizaÃ§Ã£o opcional em nuvem (futuro)
- AnÃ¡lise de progresso e estatÃ­sticas
- Suporte a mÃºltiplos idiomas

## ğŸ§  Pipeline de Reconhecimento

O sistema segue um pipeline de processamento em tempo real:

1. **Captura** â†’ Webcam captura vÃ­deo a 30 FPS
2. **ExtraÃ§Ã£o** â†’ MediaPipe Hands detecta 21 landmarks por mÃ£o (x, y, z)
3. **NormalizaÃ§Ã£o** â†’ Coordenadas normalizadas para [0, 1]
4. **Buffer** â†’ MantÃ©m janela deslizante de 30 frames (126 features por frame)
5. **InferÃªncia** â†’ Modelo LSTM processa sequÃªncia temporal
6. **PÃ³s-processamento** â†’ Threshold de confianÃ§a + debounce
7. **Feedback** â†’ Interface exibe resultado com feedback visual

## ğŸ§ª Arquitetura TÃ©cnica

### PadrÃµes de Design
- **Fat Client**: Toda lÃ³gica de negÃ³cio no navegador
- **Edge Computing**: Processamento de IA 100% client-side
- **Services Pattern**: Encapsulamento de lÃ³gica (AI, Camera, Auth)
- **Reactive Programming**: RxJS para gerenciamento de streams
- **Component-Based**: Arquitetura modular com Angular

### DecisÃµes Arquiteturais
- **Sem Backend (MVP)**: Elimina complexidade operacional e custos
- **Processamento Local**: Garante privacidade (dados nunca saem do dispositivo)
- **WebGL Acceleration**: TensorFlow.js usa GPU quando disponÃ­vel
- **LatÃªncia <50ms**: Requisito crÃ­tico atendido com edge computing

## ğŸ‘©â€ğŸ’» Desenvolvimento

Este projeto segue a **BMad Method** (Behavioral Modeling and Automated Development) para desenvolvimento estruturado e orientado a comportamento.

### Metodologia de Desenvolvimento

A BMad Method organiza o desenvolvimento em camadas:
- **Core**: Ferramentas, tarefas e workflows fundamentais
- **BMB** (Basic): Agentes bÃ¡sicos e workflows de desenvolvimento
- **BMGD** (Game Design): Agentes especializados em gamificaÃ§Ã£o
- **BMM** (ML): Agentes especializados em Machine Learning
- **CIS**: Agentes de Continuous Improvement System

### DocumentaÃ§Ã£o TÃ©cnica

#### Documentos Principais (source of truth)
- [docs/index.md](docs/index.md) - Hub de documentaÃ§Ã£o central
- [docs/prd.md](docs/prd.md) - Product Requirements Document
- [docs/architeture.md](docs/architeture.md) - DecisÃµes arquiteturais e padrÃµes tÃ©cnicos
- [docs/model-conversion.md](docs/model-conversion.md) - Guia de conversÃ£o do modelo ML
- [docs/responsividade.md](docs/responsividade.md) - EstratÃ©gia de design responsivo

#### Artefatos Gerados (BMAD)
- [_bmad-output/epics.md](_bmad-output/epics.md) - Ã‰picos e stories do projeto
- [_bmad-output/test-design-system.md](_bmad-output/test-design-system.md) - EstratÃ©gia de testes
- [_bmad-output/implementation-artifacts/](_bmad-output/implementation-artifacts/) - DocumentaÃ§Ã£o de implementaÃ§Ã£o por tarefa

### ConfiguraÃ§Ã£o do Ambiente de Desenvolvimento

#### Frontend (Angular)
```bash
cd lia-web
npm install
npm start
```

#### Machine Learning (Python)
Consulte [lia-web/SETUP-AMBIENTE.md](lia-web/SETUP-AMBIENTE.md) para configuraÃ§Ã£o completa do ambiente Python.

**Resumo:**
```powershell
# Criar ambiente virtual
python -m venv ml_venv

# Ativar
.\ml_venv\Scripts\Activate.ps1

# Instalar dependÃªncias
pip install numpy==1.24.3 protobuf==3.20.3
pip install tensorflow==2.13.0
pip install mediapipe==0.10.9 opencv-python pandas joblib
pip install scikit-learn==1.2.2
```

## ğŸ§ª Testes

O projeto utiliza Jest para testes unitÃ¡rios:

```bash
# Executar todos os testes
npm test

# Modo watch
npm run test:watch

# Com coverage
npm test -- --coverage
```

## ğŸš€ Build e Deploy

### Build de ProduÃ§Ã£o
```bash
npm run build
```

Os arquivos otimizados serÃ£o gerados em `dist/lia-web/browser/`.

### Deploy
O projeto Ã© uma aplicaÃ§Ã£o estÃ¡tica e pode ser hospedada em qualquer serviÃ§o de hosting:
- **Vercel**: Deploy automÃ¡tico via GitHub
- **Netlify**: Drag & drop ou CI/CD
- **GitHub Pages**: Para demonstraÃ§Ãµes
- **Azure Static Web Apps**: Para ambiente corporativo

### Requisitos de Hosting
- Suporte a SPA (Single Page Application)
- Rewrite rules para Angular Router
- HTTPS (necessÃ¡rio para acesso Ã  webcam)

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### ConvenÃ§Ãµes de CÃ³digo
- Seguir o guia de estilo do Angular
- Usar TypeScript strict mode
- Adicionar testes para novas funcionalidades
- Documentar funÃ§Ãµes e componentes complexos

## ğŸ“Š Status do Projeto

**Branch Atual:** `feature/development`  
**Fase:** MVP em desenvolvimento  
**Ãšltima AtualizaÃ§Ã£o:** Janeiro 2026

### Roadmap
- âœ… Fase 1: Setup inicial e arquitetura base
- âœ… Fase 2: Pipeline de reconhecimento de gestos
- ğŸ”„ Fase 3: Interface de aprendizado gamificada (em andamento)
- â³ Fase 4: Sistema de persistÃªncia e progresso
- â³ Fase 5: Testes de usabilidade e refinamentos
- â³ Fase 6: PWA e otimizaÃ§Ãµes finais

## ğŸ“„ LicenÃ§a

Projeto acadÃªmico - SIMAC 2025

## ğŸ‘¥ Autores

Desenvolvido por Joyce Peres e equipe como parte do projeto acadÃªmico SIMAC 2025.

## ğŸ“ Suporte

Para questÃµes e suporte:
- Abra uma issue no GitHub
- Consulte a documentaÃ§Ã£o em [docs/](docs/)
- Verifique os artefatos de implementaÃ§Ã£o em [_bmad-output/](_bmad-output/)

---

**LIA Web** - Democratizando o ensino de Libras com tecnologia ğŸ¤Ÿ
