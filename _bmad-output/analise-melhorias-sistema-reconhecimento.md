# An√°lise e Melhorias do Sistema de Reconhecimento de Libras

**Data:** 15 de Janeiro de 2026  
**Status:** An√°lise Completa com Propostas de Melhoria

---

## üìä ESTADO ATUAL DO SISTEMA

### Dados Coletados
- **Total de registros:** ~12MB de dados
- **Gestos coletados:** 7 gestos (A, B, E, I, N, O, U)
- **Distribui√ß√£o:**
  - E: 42 amostras ‚úÖ
  - A: 42 amostras ‚úÖ  
  - I: 41 amostras ‚úÖ
  - O: 40 amostras ‚úÖ
  - U: 40 amostras ‚úÖ
  - B: 25 amostras ‚úÖ
  - N: 17 amostras ‚ö†Ô∏è (limite m√≠nimo: 15)

### Arquitetura Atual

#### Pipeline de Coleta
```
Webcam ‚Üí MediaPipe Hands ‚Üí Landmarks (21√ó3√ó2 = 126 valores) ‚Üí 
Buffer (30 frames) ‚Üí CSV
```

#### Pipeline de Treinamento
```
CSV ‚Üí Carregamento + Valida√ß√£o ‚Üí Codifica√ß√£o de Labels ‚Üí 
Split 80/20 ‚Üí LSTM(128) + Dropout + LSTM(64) + Dense ‚Üí Modelo .h5
```

#### Pipeline de Reconhecimento (Python)
```
Webcam ‚Üí MediaPipe ‚Üí Buffer Circular (30 frames) ‚Üí 
Modelo LSTM ‚Üí Suaviza√ß√£o (vota√ß√£o majorit√°ria) ‚Üí Predi√ß√£o
```

#### Pipeline Web (React/Angular)
```
Webcam ‚Üí MediaPipe Hands ‚Üí Buffer Circular ‚Üí Normaliza√ß√£o ‚Üí 
TensorFlow.js Model ‚Üí Threshold + Debounce ‚Üí UI
```

---

## üéØ PROBLEMAS IDENTIFICADOS

### 1. **CR√çTICO: Dataset Limitado**
- **Problema:** Apenas 7 gestos coletados vs 61 gestos no modelo treinado
- **Impacto:** Modelo n√£o pode reconhecer a maioria dos gestos (alfabeto completo, n√∫meros, palavras)
- **Evid√™ncia:** CSV tem apenas A, B, E, I, N, O, U

### 2. **ALTO: Distribui√ß√£o Desbalanceada**
- **Problema:** "N" tem apenas 17 amostras (muito pr√≥ximo do m√≠nimo de 15)
- **Impacto:** Poss√≠vel overfitting ou baixa acur√°cia para esse gesto
- **Recomenda√ß√£o:** M√≠nimo de 30-50 amostras por gesto para estabilidade

### 3. **M√âDIO: Falta de Data Augmentation**
- **Problema:** Scripts de coleta n√£o aplicam augmentation
- **Impacto:** Modelo pode n√£o generalizar bem com varia√ß√µes de:
  - √Çngulo de c√¢mera
  - Dist√¢ncia da m√£o
  - Ilumina√ß√£o
  - Velocidade do movimento
  - Posi√ß√£o lateral (esquerda/direita/centro)

### 4. **M√âDIO: Sem Valida√ß√£o de Qualidade na Coleta**
- **Problema:** Script aceita qualquer captura, mesmo com:
  - M√£os parcialmente vis√≠veis
  - Landmarks com baixa confian√ßa
  - Movimentos bruscos (blur)
  - Oclus√µes
- **Impacto:** Dados ruidosos no dataset

### 5. **BAIXO: Reconhecimento Limpa Buffer Ap√≥s Sucesso**
- **Problema:** Em `reconhecer_gestos.py`, linha ~180: `self.buffer.clear()` ap√≥s reconhecimento
- **Impacto:** N√£o permite reconhecer m√∫ltiplos gestos em sequ√™ncia sem pausa
- **Para ensino:** Pode ser frustrante para o usu√°rio

### 6. **BAIXO: Falta de Feedback Pedag√≥gico**
- **Problema:** Sistema apenas reconhece gestos, n√£o ensina
- **Impacto:** Usu√°rio n√£o sabe:
  - Se est√° fazendo o gesto corretamente
  - Quais erros est√° cometendo
  - Como melhorar

---

## üí° MELHORIAS PROPOSTAS

### üî¥ PRIORIDADE CR√çTICA

#### M1: Completar o Dataset
**Objetivo:** Coletar dados para todos os 61 gestos do modelo

```python
# Lista de gestos faltantes
GESTOS_ALFABETO = ['A', 'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z']
GESTOS_NUMEROS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
GESTOS_PALAVRAS = ['TCHAU', 'OBRIGADA', 'DESCULPA', 'POR FAVOR', 'TUDO BEM', 
                   'AGORA', 'ONTEM', 'AMANHA', 'SEGUNDA', 'TERCA', 'QUARTA', 
                   'QUINTA', 'SEXTA', 'SABADO', 'DOMINGO', 'ANO', 'MES', 
                   'HORAS', 'MINUTOS', 'ONDE', 'QUANDO', 'POR QUE', 
                   'PAI', 'ADOCANTE', 'ABAIXO']

META_MINIMA_POR_GESTO = 50  # Aumentar de 15 para 50
META_IDEAL_POR_GESTO = 100  # Para melhor generaliza√ß√£o
```

**Implementa√ß√£o:**
1. Adicionar modo "coleta em lote" com lista de gestos
2. Mostrar progresso por gesto
3. Validar qualidade (ver M2)

#### M2: Valida√ß√£o de Qualidade na Coleta
**Objetivo:** Aceitar apenas amostras de alta qualidade

```python
def validar_qualidade_frame(results, frame) -> tuple[bool, str]:
    """
    Valida se o frame tem qualidade suficiente para ser usado no treinamento.
    
    Returns:
        (is_valid, mensagem_erro)
    """
    if not results.multi_hand_landmarks:
        return False, "Nenhuma m√£o detectada"
    
    # 1. Verificar n√∫mero de m√£os (idealmente 1 para alfabeto, 2 para alguns sinais)
    num_hands = len(results.multi_hand_landmarks)
    
    # 2. Verificar confian√ßa dos landmarks
    for hand_landmarks in results.multi_hand_landmarks:
        # Landmarks devem estar dentro de uma regi√£o razo√°vel
        xs = [lm.x for lm in hand_landmarks.landmark]
        ys = [lm.y for lm in hand_landmarks.landmark]
        
        # M√£o muito pequena (longe demais)
        hand_width = max(xs) - min(xs)
        hand_height = max(ys) - min(ys)
        if hand_width < 0.15 or hand_height < 0.15:
            return False, "M√£o muito pequena - aproxime-se da c√¢mera"
        
        # M√£o cortada nas bordas
        if min(xs) < 0.05 or max(xs) > 0.95 or min(ys) < 0.05 or max(ys) > 0.95:
            return False, "M√£o cortada - centralize na c√¢mera"
    
    # 3. Verificar estabilidade (evitar motion blur)
    # Implementar compara√ß√£o com frame anterior (opcional)
    
    return True, "OK"


def validar_qualidade_sequencia(buffer) -> tuple[bool, str]:
    """
    Valida se a sequ√™ncia inteira tem qualidade suficiente.
    """
    if len(buffer) < MIN_FRAMES:
        return False, f"Poucos frames ({len(buffer)} < {MIN_FRAMES})"
    
    # Verificar estabilidade: n√£o deve ter muita varia√ß√£o
    # (indicaria movimento brusco ou troca de gesto no meio)
    variances = []
    for i in range(len(buffer) - 1):
        diff = np.abs(buffer[i] - buffer[i+1]).sum()
        variances.append(diff)
    
    mean_var = np.mean(variances)
    if mean_var > THRESHOLD_VARIACAO:  # definir empiricamente
        return False, "Movimento muito brusco - fa√ßa o gesto mais devagar"
    
    return True, "OK"
```

### üü° PRIORIDADE ALTA

#### M3: Data Augmentation Offline
**Objetivo:** Aumentar dataset artificialmente com transforma√ß√µes realistas

```python
import numpy as np

def augment_landmarks(landmarks: np.ndarray, num_augments: int = 5) -> list[np.ndarray]:
    """
    Gera varia√ß√µes realistas de uma sequ√™ncia de landmarks.
    
    Transforma√ß√µes:
    - Rota√ß√£o: simula diferentes √¢ngulos de c√¢mera
    - Escala: simula diferentes dist√¢ncias
    - Transla√ß√£o: simula posi√ß√£o na tela
    - Ru√≠do gaussiano: simula imprecis√£o do MediaPipe
    - Espelhamento horizontal: simula m√£o esquerda/direita
    """
    augmented = []
    
    for _ in range(num_augments):
        aug = landmarks.copy()
        
        # 1. Rota√ß√£o leve (-15¬∞ a +15¬∞)
        angle = np.random.uniform(-15, 15) * np.pi / 180
        for frame_idx in range(aug.shape[0]):
            for hand_idx in range(0, 42, 21):  # cada m√£o
                # Rotacionar apenas x, y (z permanece)
                for lm_idx in range(21):
                    idx = (hand_idx + lm_idx) * 3
                    x, y = aug[frame_idx, idx], aug[frame_idx, idx+1]
                    
                    # Rota√ß√£o em torno do centro da m√£o
                    center_x = aug[frame_idx, idx:(idx+63):3].mean()
                    center_y = aug[frame_idx, idx+1:(idx+63):3].mean()
                    
                    x_rot = (x - center_x) * np.cos(angle) - (y - center_y) * np.sin(angle) + center_x
                    y_rot = (x - center_x) * np.sin(angle) + (y - center_y) * np.cos(angle) + center_y
                    
                    aug[frame_idx, idx] = x_rot
                    aug[frame_idx, idx+1] = y_rot
        
        # 2. Escala (90% a 110%)
        scale = np.random.uniform(0.9, 1.1)
        aug[:, ::3] *= scale  # x
        aug[:, 1::3] *= scale  # y
        
        # 3. Transla√ß√£o (-10% a +10%)
        shift_x = np.random.uniform(-0.1, 0.1)
        shift_y = np.random.uniform(-0.1, 0.1)
        aug[:, ::3] += shift_x  # x
        aug[:, 1::3] += shift_y  # y
        
        # 4. Ru√≠do gaussiano (œÉ = 0.005)
        noise = np.random.normal(0, 0.005, aug.shape)
        aug += noise
        
        # 5. Espelhamento horizontal (50% chance)
        if np.random.rand() > 0.5:
            aug[:, ::3] = 1 - aug[:, ::3]  # x espelhado
        
        # Garantir que landmarks permanecem no range [0, 1]
        aug = np.clip(aug, 0, 1)
        
        augmented.append(aug)
    
    return augmented


def augmentar_dataset(csv_path: Path, output_path: Path, augments_per_sample: int = 5):
    """
    L√™ CSV original e gera vers√£o aumentada.
    """
    df = pd.read_csv(csv_path)
    
    registros_aumentados = []
    
    for idx, row in df.iterrows():
        # Original
        registros_aumentados.append(row)
        
        # Augmentations
        frames_original = np.array(ast.literal_eval(row['frames']))
        augmented_samples = augment_landmarks(frames_original, augments_per_sample)
        
        for aug_idx, aug_frames in enumerate(augmented_samples):
            novo_registro = row.copy()
            novo_registro['frames'] = aug_frames.tolist()
            novo_registro['timestamp'] = f"{row['timestamp']}_aug{aug_idx}"
            registros_aumentados.append(novo_registro)
    
    df_aug = pd.DataFrame(registros_aumentados)
    df_aug.to_csv(output_path, index=False)
    
    print(f"Dataset aumentado: {len(df)} ‚Üí {len(df_aug)} amostras")
```

#### M4: Modo de Pr√°tica com Feedback Pedag√≥gico
**Objetivo:** Sistema que ENSINA, n√£o apenas reconhece

```python
class PracticeMode:
    """
    Modo de pr√°tica que fornece feedback em tempo real.
    """
    
    def __init__(self, gesto_alvo: str):
        self.gesto_alvo = gesto_alvo
        self.gesto_referencia = self.carregar_referencia(gesto_alvo)
        
    def calcular_similaridade(self, landmarks_usuario: np.ndarray) -> float:
        """
        Calcula dist√¢ncia entre gesto do usu√°rio e refer√™ncia.
        Usa DTW (Dynamic Time Warping) para alinhar temporalmente.
        """
        from scipy.spatial.distance import euclidean
        from dtaidistance import dtw
        
        # DTW entre landmarks do usu√°rio e refer√™ncia
        distancia = dtw.distance(
            landmarks_usuario.reshape(-1), 
            self.gesto_referencia.reshape(-1)
        )
        
        # Normalizar para [0, 1] (similaridade)
        max_dist = 100  # definir empiricamente
        similaridade = max(0, 1 - distancia / max_dist)
        
        return similaridade
    
    def gerar_feedback_visual(self, frame, landmarks_usuario, landmarks_referencia):
        """
        Desenha compara√ß√£o visual entre gesto do usu√°rio e refer√™ncia.
        """
        h, w = frame.shape[:2]
        
        # Split screen: usu√°rio (esquerda) vs refer√™ncia (direita)
        frame_split = np.zeros((h, w*2, 3), dtype=np.uint8)
        frame_split[:, :w] = frame  # usu√°rio
        
        # Desenhar refer√™ncia do lado direito
        ref_frame = np.zeros((h, w, 3), dtype=np.uint8)
        self.desenhar_landmarks_referencia(ref_frame, landmarks_referencia)
        frame_split[:, w:] = ref_frame
        
        # Linha divis√≥ria
        cv2.line(frame_split, (w, 0), (w, h), (255, 255, 255), 2)
        
        # Labels
        cv2.putText(frame_split, "Voc√™", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(frame_split, "Refer√™ncia", (w + 20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        return frame_split
    
    def gerar_feedback_textual(self, similaridade: float) -> str:
        """
        Gera dicas textuais baseadas na similaridade.
        """
        if similaridade > 0.9:
            return "‚úÖ Perfeito! Gesto correto!"
        elif similaridade > 0.75:
            return "‚ú® Muito bom! Pequenos ajustes..."
        elif similaridade > 0.6:
            return "üìç Quase l√°! Ajuste a posi√ß√£o dos dedos"
        elif similaridade > 0.4:
            return "üîÑ Continue tentando... Observe a refer√™ncia"
        else:
            return "‚ùå Gesto muito diferente. Tente novamente"
```

#### M5: Sistema de Progress√£o Gamificado
**Objetivo:** Motivar usu√°rio a completar todos os gestos

```python
class ProgressionSystem:
    """
    Sistema de n√≠veis e conquistas para motivar aprendizado.
    """
    
    NIVEIS = {
        'iniciante': {
            'gestos': ['A', 'B', 'C', 'D', 'E'],
            'min_acertos': 3
        },
        'intermediario': {
            'gestos': list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'),
            'min_acertos': 5
        },
        'avancado': {
            'gestos': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],
            'min_acertos': 7
        },
        'expert': {
            'gestos': ['TCHAU', 'OBRIGADA', 'POR FAVOR', 'TUDO BEM'],
            'min_acertos': 10
        }
    }
    
    def calcular_nivel(self, historico: dict) -> str:
        """
        Determina n√≠vel atual do usu√°rio baseado no hist√≥rico.
        """
        for nivel, config in self.NIVEIS.items():
            acertos = sum(
                1 for gesto in config['gestos']
                if historico.get(gesto, 0) >= config['min_acertos']
            )
            if acertos < len(config['gestos']):
                return nivel
        
        return 'mestre'
    
    def sugerir_proximo_gesto(self, historico: dict) -> str:
        """
        Sugere pr√≥ximo gesto que o usu√°rio deve praticar.
        """
        nivel_atual = self.calcular_nivel(historico)
        gestos_nivel = self.NIVEIS[nivel_atual]['gestos']
        
        # Encontrar gesto com menos pr√°tica
        return min(gestos_nivel, key=lambda g: historico.get(g, 0))
    
    def gerar_conquistas(self, historico: dict) -> list:
        """
        Lista de conquistas desbloqueadas.
        """
        conquistas = []
        
        # Conquistas por quantidade
        total_acertos = sum(historico.values())
        if total_acertos >= 100:
            conquistas.append("üèÜ Centuri√£o - 100 gestos reconhecidos")
        if total_acertos >= 500:
            conquistas.append("üíé Mestre - 500 gestos reconhecidos")
        
        # Conquistas por completude
        if len(historico) >= 26:
            conquistas.append("üî§ Alfabeto Completo")
        if all(historico.get(str(i), 0) > 0 for i in range(11)):
            conquistas.append("üî¢ Contador - Todos os n√∫meros")
        
        return conquistas
```

### üü¢ PRIORIDADE M√âDIA

#### M6: Detec√ß√£o de Erros Comuns
**Objetivo:** Identificar e corrigir erros espec√≠ficos de cada gesto

```python
ERROS_COMUNS = {
    'A': [
        {'descricao': 'Polegar n√£o est√° ao lado da m√£o', 
         'check': lambda lm: lm[4][0] > lm[9][0]},  # polegar deve estar √† esquerda do √≠ndice
        {'descricao': 'Dedos n√£o est√£o fechados',
         'check': lambda lm: np.mean([lm[i][1] for i in [8,12,16,20]]) > lm[0][1] + 0.1}
    ],
    'B': [
        {'descricao': 'Dedos n√£o est√£o juntos',
         'check': lambda lm: max_distance_between_fingers(lm) > 0.05},
        {'descricao': 'Polegar n√£o est√° dobrado',
         'check': lambda lm: lm[4][0] > lm[2][0]}  # polegar deve estar dentro
    ],
    # ... outros gestos
}

def detectar_erro(gesto: str, landmarks: np.ndarray) -> str | None:
    """
    Detecta erro espec√≠fico no gesto atual.
    """
    if gesto not in ERROS_COMUNS:
        return None
    
    for erro in ERROS_COMUNS[gesto]:
        if not erro['check'](landmarks):
            return erro['descricao']
    
    return None
```

#### M7: Exporta√ß√£o de M√©tricas de Aprendizado
**Objetivo:** Permitir que professores acompanhem progresso dos alunos

```python
def gerar_relatorio_progresso(usuario: str, historico: dict) -> dict:
    """
    Gera relat√≥rio detalhado de progresso.
    """
    return {
        'usuario': usuario,
        'nivel': calcular_nivel(historico),
        'total_gestos_praticados': len(historico),
        'total_acertos': sum(historico.values()),
        'taxa_acerto_media': np.mean(list(historico.values())),
        'gestos_dominados': [g for g, count in historico.items() if count >= 10],
        'gestos_em_progresso': [g for g, count in historico.items() if 0 < count < 10],
        'gestos_nao_praticados': [g for g in TODOS_GESTOS if g not in historico],
        'tempo_total_pratica': calcular_tempo_total(),
        'conquistas': gerar_conquistas(historico),
        'grafico_evolucao': gerar_grafico_temporal(historico)
    }
```

#### M8: Reconhecimento Cont√≠nuo Sem Reset Autom√°tico
**Objetivo:** Permitir frases/sequ√™ncias de gestos

```python
class ContinuousRecognizer:
    """
    Reconhecedor que mant√©m hist√≥rico e detecta pausas naturais.
    """
    
    def __init__(self):
        self.buffer = deque(maxlen=SEQUENCE_LENGTH)
        self.sequencia_reconhecida = []
        self.frames_sem_movimento = 0
        
    def processar_frame(self, landmarks):
        self.buffer.append(landmarks)
        
        # Detectar pausa (pouco movimento)
        if len(self.buffer) >= 2:
            movimento = np.abs(self.buffer[-1] - self.buffer[-2]).sum()
            if movimento < THRESHOLD_PAUSA:
                self.frames_sem_movimento += 1
            else:
                self.frames_sem_movimento = 0
        
        # Reconhecer quando buffer cheio E h√° movimento
        if len(self.buffer) == SEQUENCE_LENGTH and self.frames_sem_movimento < 5:
            gesto = self.model.predict(self.buffer)
            if gesto:
                self.sequencia_reconhecida.append(gesto)
                # N√ÉO limpar buffer - apenas deslizar
                # self.buffer.clear()  # REMOVER isto!
        
        # Reset apenas em pausas longas (indica fim da frase)
        if self.frames_sem_movimento > 30:
            if self.sequencia_reconhecida:
                frase = ' '.join(self.sequencia_reconhecida)
                print(f"Frase reconhecida: {frase}")
                self.sequencia_reconhecida = []
```

---

## üìã PLANO DE IMPLEMENTA√á√ÉO

### Sprint 1: Melhorias Cr√≠ticas (1-2 semanas)
- ‚úÖ **M1:** Script automatizado de coleta em lote
- ‚úÖ **M2:** Valida√ß√£o de qualidade na coleta
- üìä Meta: Coletar dataset completo (61 gestos √ó 50 amostras = ~3050 registros)

### Sprint 2: Melhorias de Treinamento (1 semana)
- ‚úÖ **M3:** Implementar data augmentation
- üîÑ Retreinar modelo com dataset completo e aumentado
- üìä Meta: Acur√°cia > 95%

### Sprint 3: Melhorias Pedag√≥gicas (2 semanas)
- ‚úÖ **M4:** Modo de pr√°tica com feedback visual
- ‚úÖ **M5:** Sistema de progress√£o gamificado
- ‚úÖ **M6:** Detec√ß√£o de erros comuns

### Sprint 4: Refinamentos (1 semana)
- ‚úÖ **M7:** Exporta√ß√£o de m√©tricas
- ‚úÖ **M8:** Reconhecimento cont√≠nuo
- üß™ Testes com usu√°rios reais

---

## üéØ M√âTRICAS DE SUCESSO

### T√©cnicas
- ‚úÖ Acur√°cia do modelo > 95%
- ‚úÖ Taxa de falsos positivos < 5%
- ‚úÖ Lat√™ncia de reconhecimento < 100ms
- ‚úÖ Dataset balanceado (varia√ß√£o < 20% entre gestos)

### Pedag√≥gicas
- ‚úÖ Tempo m√©dio para dominar um gesto < 10 minutos
- ‚úÖ Taxa de reten√ß√£o ap√≥s 1 semana > 80%
- ‚úÖ Satisfa√ß√£o do usu√°rio > 4.5/5
- ‚úÖ Taxa de completude do alfabeto > 70%

---

## üöÄ QUICK WINS (Implementa√ß√£o R√°pida)

### 1. Aumentar M√≠nimo de Amostras
```python
# Em treinar_modelo.py, linha ~31
MIN_AMOSTRAS = 30  # Aumentar de 15 para 30
```

### 2. Adicionar Contador Visual na Coleta
```python
# Em coletar_gestos.py, adicionar ap√≥s linha ~220
amostras_existentes = contar_amostras_existentes()
faltantes = {gesto: max(0, 30 - amostras_existentes.get(gesto, 0)) 
             for gesto in TODOS_GESTOS}
print(f"\nüìä Progresso geral: {len([g for g, f in faltantes.items() if f == 0])}/{len(TODOS_GESTOS)} completos")
```

### 3. Salvar Hist√≥rico de Reconhecimento
```python
# Em reconhecer_gestos.py, adicionar logging
import json
from datetime import datetime

historico_path = Path('historico_reconhecimento.json')
historico = json.load(historico_path.open()) if historico_path.exists() else {}

# Ao reconhecer um gesto (linha ~390):
historico[gesto] = historico.get(gesto, 0) + 1
historico['_last_session'] = datetime.now().isoformat()
json.dump(historico, historico_path.open('w'), indent=2)
```

---

## üìö REFER√äNCIAS E RECURSOS

### Papers Relevantes
1. **Data Augmentation for Sign Language Recognition**
   - Transforma√ß√µes geom√©tricas em landmarks 3D
   - Aumento de 5-10x no dataset

2. **DTW for Gesture Similarity**
   - Dynamic Time Warping para compara√ß√£o temporal
   - Robusto a varia√ß√µes de velocidade

3. **Gamification in Education**
   - Sistemas de progress√£o aumentam engajamento em 40%
   - Feedback imediato melhora aprendizado em 30%

### Bibliotecas √öteis
- `albumentations`: Data augmentation para vis√£o computacional
- `dtaidistance`: Implementa√ß√£o eficiente de DTW
- `scikit-learn`: M√©tricas de avalia√ß√£o e valida√ß√£o cruzada

---

## ‚úÖ CONCLUS√ÉO

O sistema atual tem uma **base s√≥lida**, mas precisa de:

1. **Dataset completo** (cr√≠tico para funcionar)
2. **Melhor qualidade de dados** (valida√ß√£o + augmentation)
3. **Feedback pedag√≥gico** (transformar em ferramenta de ensino)

Com essas melhorias, o LIA pode se tornar uma plataforma **eficaz e engajadora** para ensino de Libras.

**Pr√≥ximos passos imediatos:**
1. Executar coleta em lote para completar dataset
2. Aplicar augmentation e retreinar
3. Implementar modo de pr√°tica b√°sico
